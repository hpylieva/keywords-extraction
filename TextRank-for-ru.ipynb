{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of TextRank\n",
    "(Based on: https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input text is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:09:18.439140Z",
     "start_time": "2018-11-05T13:09:18.425522Z"
    }
   },
   "outputs": [],
   "source": [
    "#Source of text:\n",
    "#https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents\n",
    "\n",
    "Text = u\"\"\"\n",
    "    Одной из популярных позиций нашего производства является угловой диван Респект. Если Вы современный и деловой человек, любите комфорт и уют, а каждый сантиметр жилплощади для Вас на вес золота – тогда угловой диван Респект отлично впишется в интерьер Вашей квартиры, заняв при этом минимум места. Угловой диван Респект не только практичен в использовании, удобен, мягок и современен, но и еще удивительно компактен. В его изготовлении используются только самые экологически чистые ткани и наполнители, а механизм раскладки еврокнижка - поможет Вам сэкономить массу усилий и времени для его преобразования в полноценную кровать.\n",
    "     Модель со схемой раскладки еврокнижка, сделана на основе деревянного каркаса с использованием пружины типа Боннель в паре с пружинной змейкой.\n",
    "Особенностью этого дивана является небольшой габаритный размер короткой части модели 135см, что позволяет устанавливать его в наши малогабаритные квартиры. Стильные боковые перила в виде полудуги придают угловому дивану Респект чрезвычайной элегантности.\n",
    "     Как и в большинстве моделей нашего производства в модели Респект есть возможность добавления на спальную и сидячую части натуральных наполнителей (кокос, латекс, спрут, шерсть и др.), что придаст модели более выраженный ортопедический эффект. В конструкцию углового дивана заложено два больших места для хранения постельного белья, одно под сидячей продольной частью, второе в угловой части. Угловой диван Респект комплектуется тремя большими подушками для удобного сидения в собранном виде.\n",
    "     Все материалы, которые используются при производстве углового дивана Респект проверены и сертифицированы, на весь модельный ряд и в частности на эту модель распространяется гарантийное и послегарантийное обслуживание.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:58:45.921452Z",
     "start_time": "2018-11-05T13:58:45.912145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    nltk.data.find('averaged_perceptron_tagger_ru')\n",
    "except LookupError:\n",
    "    print('bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Text Data\n",
    "\n",
    "The raw input text is cleaned off non-printable characters (if any) and turned into lower case.\n",
    "The processed input text is then tokenized using NLTK library functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-06T14:14:09.275678Z",
     "start_time": "2018-11-06T14:14:09.260233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Text: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, RegexpTokenizer\n",
    "import string\n",
    "\n",
    "#nltk.download('punkt')\n",
    "cyrrilic = \"абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ\"\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    printable = set(cyrrilic + string.printable)\n",
    "#     print(printable)\n",
    "    text = re.sub(\"[^{}]\".format(printable), '', text) #filter funny characters, if any.\n",
    "    return text\n",
    "\n",
    "Cleaned_text = clean(Text)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "text = tokenizer.tokenize(Cleaned_text)\n",
    "\n",
    "print( \"Tokenized Text: \\n\")\n",
    "# print (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging For Lemmatization\n",
    "\n",
    "NLTK is again used for <b>POS tagging</b> the input text so that the words can be lemmatized based on their POS tags.\n",
    "\n",
    "Description of POS tags: \n",
    "\n",
    "- English\n",
    "http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "- Russian (from Russian National Corpus tagset)\n",
    "http://www.ruscorpora.ru/en/corpora-morph.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:09:26.832173Z",
     "start_time": "2018-11-05T13:09:26.492526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     /home/h.pylieva/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T10:11:36.491316Z",
     "start_time": "2018-11-05T10:11:36.486101Z"
    }
   },
   "outputs": [],
   "source": [
    "# #nltk.download('averaged_perceptron_tagger')\n",
    "  \n",
    "# POS_tag = nltk.pos_tag(text, lang='rus')\n",
    "\n",
    "# print(\"Tokenized Text with POS tags: \\n\")\n",
    "# print(POS_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "The tokenized text (mainly the nouns and adjectives) is normalized by <b>lemmatization</b>.\n",
    "In lemmatization different grammatical counterparts of a word will be replaced by single\n",
    "basic lemma. For example, 'glasses' may be replaced by 'glass'. \n",
    "\n",
    "Details about lemmatization: \n",
    "    \n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:09:33.514475Z",
     "start_time": "2018-11-05T13:09:33.290685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tokens after lemmatization of adjectives and nouns: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adj_type = ['A','A-NUM']\n",
    "# spec = ['m', 'f', 'pl', 'n']\n",
    "# adjective_tags = ['='.join([t,s]) for t in adj_type for s in spec]\n",
    "# for English version ['JJ','JJR','JJS']\n",
    "\n",
    "# lemmatized_text = []\n",
    "\n",
    "# for word in POS_tag:\n",
    "#     if word[1] in adjective_tags:\n",
    "#         lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0],pos=\"a\")))\n",
    "#     else:\n",
    "#         lemmatized_text.append(str(wordnet_lemmatizer.lemmatize(word[0]))) #default POS = noun\n",
    "lemmatized_text =  [morph_ru.parse(word)[0].normal_form for word in text]        \n",
    "print (\"Text tokens after lemmatization of adjectives and nouns: \\n\")\n",
    "# print (lemmatized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging for Filtering\n",
    "\n",
    "The <b>lemmatized text</b> is <b>POS tagged</b> here. The tags will be used for filtering later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:09:36.974024Z",
     "start_time": "2018-11-05T13:09:36.629926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized text with POS tags: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "POS_tag = nltk.pos_tag(lemmatized_text, lang='rus')\n",
    "\n",
    "print (\"Lemmatized text with POS tags: \\n\")\n",
    "# print (POS_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T10:13:11.282837Z",
     "start_time": "2018-11-05T10:13:11.278044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A-PRO=m', 'A-PRO=pl', 'A=f', 'A=m', 'ADV', 'ADV-PRO', 'ANUM=f',\n",
       "       'CONJ', 'NUM=acc', 'NUM=ciph', 'NUM=m', 'PART', 'PR', 'S', 'S-PRO',\n",
       "       'V'], dtype='<U8')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(list(zip(*POS_tag))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Based Filtering\n",
    "\n",
    "Any word from the lemmatized text, which isn't a noun, adjective, or gerund (or a 'foreign word'), is here\n",
    "considered as a <b>stopword</b> (non-content). This is based on the assumption that usually keywords are noun,\n",
    "adjectives or gerunds. \n",
    "\n",
    "Punctuations are added to the stopword list too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:04.527163Z",
     "start_time": "2018-11-05T13:10:04.516404Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "stopwords = []\n",
    "\n",
    "# adj_type = ['A', 'A-PRO']\n",
    "# spec = ['m', 'f', 'pl', 'n']\n",
    "# adjective_tags = ['='.join([t,s]) for t in adj_type for s in spec]\n",
    "adjective_tags = ['A=m', 'A=f', 'A=pl', 'A=n', 'A-NUM']\n",
    "\n",
    "wanted_POS = ['S',\n",
    "#               'V'\n",
    "             ] + adjective_tags\n",
    "# for English ['NN','NNS','NNP','NNPS','JJ','JJR','JJS','VBG','FW'] \n",
    "\n",
    "for word in POS_tag:\n",
    "    if word[1] not in wanted_POS:\n",
    "        stopwords.append(word[0])\n",
    "\n",
    "punctuations = list(str(string.punctuation))\n",
    "\n",
    "stopwords = stopwords + punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete stopword generation\n",
    "\n",
    "Even if we remove the aforementioned stopwords, still some extremely common nouns, adjectives or gerunds may\n",
    "remain which are very bad candidates for being keywords (or part of it). \n",
    "\n",
    "An external file constituting a long list of stopwords is loaded and all the words are added with the previous\n",
    "stopwords to create the final list 'stopwords-plus' which is then converted into a set. \n",
    "\n",
    "(Source of stopwords data: https://www.ranks.nl/stopwords)\n",
    "\n",
    "Stopwords-plus constitute the sum total of all stopwords and potential phrase-delimiters. \n",
    "\n",
    "(The contents of this set will be later used to partition the lemmatized text into n-gram phrases. But, for now, I will simply remove the stopwords, and work with a 'bag-of-words' approach. I will be developing the graph using unigram texts as vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:36.312293Z",
     "start_time": "2018-11-05T13:10:36.294595Z"
    }
   },
   "outputs": [],
   "source": [
    "stopword_file = open(\"long_stopwords_ru.txt\", \"r\")\n",
    "#Source = https://www.ranks.nl/stopwords\n",
    "\n",
    "lots_of_stopwords = []\n",
    "\n",
    "for line in stopword_file.readlines():\n",
    "    lots_of_stopwords.append(str(line.strip()))\n",
    "\n",
    "stopwords_plus = []\n",
    "stopwords_plus = stopwords + lots_of_stopwords\n",
    "stopwords_plus = set(stopwords_plus)\n",
    "\n",
    "#Stopwords_plus contain total set of all stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords \n",
    "\n",
    "Removing stopwords from lemmatized_text. \n",
    "Processeced_text condtains the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:38.110249Z",
     "start_time": "2018-11-05T13:10:38.103089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['популярный', 'позиция', 'производство', 'угловой', 'диван', 'респект', 'современный', 'деловой', 'комфорт', 'уют', 'сантиметр', 'жилплощадь', 'вес', 'золото', 'угловой', 'диван', 'респект', 'интерьер', 'квартира', 'минимум', 'место', 'угловой', 'диван', 'респект', 'использование', 'удобный', 'мягкий', 'современный', 'компактный', 'изготовление', 'чистый', 'ткань', 'наполнитель', 'механизм', 'раскладка', 'еврокнижка', 'масса', 'усилие', 'преобразование', 'полноценный', 'кровать', 'модель', 'схема', 'раскладка', 'еврокнижка', 'основа', 'деревянный', 'каркас', 'использование', 'пружина', 'тип', 'боннель', 'пар', 'пружинный', 'змейка', 'особенность', 'диван', 'небольшой', 'габаритный', 'размер', 'короткий', 'часть', 'модель', 'малогабаритный', 'квартира', 'стильный', 'боковой', 'вид', 'полудуга', 'угловой', 'диван', 'респект', 'чрезвычайный', 'элегантность', 'большинство', 'модель', 'производство', 'модель', 'респект', 'возможность', 'добавление', 'спальная', 'сидячий', 'часть', 'натуральный', 'наполнитель', 'кокос', 'латекс', 'шерсть', 'модель', 'ортопедический', 'эффект', 'конструкция', 'угловой', 'диван', 'больший', 'место', 'хранение', 'постельный', 'бельё', 'сидячий', 'продольный', 'часть', 'угловой', 'часть', 'угловой', 'диван', 'респект', 'больший', 'подушка', 'удобный', 'сидение', 'собранный', 'вид', 'материал', 'производство', 'угловой', 'диван', 'респект', 'модельный', 'ряд', 'частность', 'модель', 'гарантийный', 'послегарантийный', 'обслуживание']\n"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "for word in lemmatized_text:\n",
    "    if word not in stopwords_plus:\n",
    "        processed_text.append(word)\n",
    "print (processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Creation\n",
    "\n",
    "Vocabulary will only contain unique words from processed_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:40.555926Z",
     "start_time": "2018-11-05T13:10:40.547832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['больший', 'сантиметр', 'популярный', 'использование', 'латекс', 'масса', 'усилие', 'элегантность', 'возможность', 'размер', 'место', 'собранный', 'послегарантийный', 'мягкий', 'компактный', 'жилплощадь', 'современный', 'производство', 'пружинный', 'вид', 'еврокнижка', 'чрезвычайный', 'продольный', 'модельный', 'обслуживание', 'эффект', 'ткань', 'основа', 'конструкция', 'габаритный', 'тип', 'гарантийный', 'изготовление', 'золото', 'респект', 'чистый', 'полудуга', 'боковой', 'удобный', 'комфорт', 'схема', 'стильный', 'пар', 'минимум', 'пружина', 'короткий', 'сидячий', 'раскладка', 'шерсть', 'постельный', 'материал', 'вес', 'ортопедический', 'деревянный', 'небольшой', 'модель', 'бельё', 'наполнитель', 'добавление', 'уют', 'натуральный', 'диван', 'механизм', 'деловой', 'особенность', 'часть', 'сидение', 'преобразование', 'хранение', 'спальная', 'позиция', 'большинство', 'ряд', 'каркас', 'интерьер', 'боннель', 'полноценный', 'кровать', 'кокос', 'подушка', 'частность', 'квартира', 'малогабаритный', 'угловой', 'змейка']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(set(processed_text))\n",
    "print (vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Graph\n",
    "\n",
    "TextRank is a graph based model, and thus it requires us to build a graph. Each words in the vocabulary will serve as a vertex for graph. The words will be represented in the vertices by their index in vocabulary list.  \n",
    "\n",
    "The weighted_edge matrix contains the information of edge connections among all vertices.\n",
    "I am building wieghted undirected edges.\n",
    "\n",
    "weighted_edge[i][j] contains the weight of the connecting edge between the word vertex represented by vocabulary index i and the word vertex represented by vocabulary j.\n",
    "\n",
    "If weighted_edge[i][j] is zero, it means no edge connection is present between the words represented by index i and j.\n",
    "\n",
    "There is a connection between the words (and thus between i and j which represents them) if the words co-occur within a window of a specified 'window_size' in the processed_text.\n",
    "\n",
    "The value of the weighted_edge[i][j] is increased by (1/(distance between positions of words currently represented by i and j)) for every connection discovered between the same words in different locations of the text. \n",
    "\n",
    "The covered_coocurrences list (which is contain the list of pairs of absolute positions in processed_text of the words whose coocurrence at that location is already checked) is managed so that the same two words located in the same positions in processed_text are not repetitively counted while sliding the window one text unit at a time.\n",
    "\n",
    "The score of all vertices are intialized to one. \n",
    "\n",
    "Self-connections are not considered, so weighted_edge[i][i] will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:42.658568Z",
     "start_time": "2018-11-05T13:10:42.415854Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "vocab_len = len(vocabulary)\n",
    "\n",
    "weighted_edge = np.zeros((vocab_len,vocab_len),dtype=np.float32)\n",
    "\n",
    "score = np.zeros((vocab_len),dtype=np.float32)\n",
    "window_size = 3\n",
    "covered_coocurrences = []\n",
    "\n",
    "for i in range(0,vocab_len):\n",
    "    score[i]=1\n",
    "    for j in range(0,vocab_len):\n",
    "        if j==i:\n",
    "            weighted_edge[i][j]=0\n",
    "        else:\n",
    "            for window_start in range(0,(len(processed_text)-window_size)):\n",
    "                \n",
    "                window_end = window_start+window_size\n",
    "                \n",
    "                window = processed_text[window_start:window_end]\n",
    "                \n",
    "                if (vocabulary[i] in window) and (vocabulary[j] in window):\n",
    "                    \n",
    "                    index_of_i = window_start + window.index(vocabulary[i])\n",
    "                    index_of_j = window_start + window.index(vocabulary[j])\n",
    "                    \n",
    "                    # index_of_x is the absolute position of the xth term in the window \n",
    "                    # (counting from 0) \n",
    "                    # in the processed_text\n",
    "                      \n",
    "                    if [index_of_i,index_of_j] not in covered_coocurrences:\n",
    "                        weighted_edge[i][j]+=1/math.fabs(index_of_i-index_of_j)\n",
    "                        covered_coocurrences.append([index_of_i,index_of_j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating weighted summation of connections of a vertex\n",
    "\n",
    "inout[i] will contain the sum of all the undirected connections\\edges associated withe the vertex represented by i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:44.187319Z",
     "start_time": "2018-11-05T13:10:44.179804Z"
    }
   },
   "outputs": [],
   "source": [
    "inout = np.zeros((vocab_len),dtype=np.float32)\n",
    "\n",
    "for i in range(0,vocab_len):\n",
    "    for j in range(0,vocab_len):\n",
    "        inout[i]+=weighted_edge[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Vertices\n",
    "\n",
    "The formula used for scoring a vertex represented by i is:\n",
    "\n",
    "score[i] = (1-d) + d x [ Summation(j) ( (weighted_edge[i][j]/inout[j]) x score[j] ) ] where j belongs to the list of vertieces that has a connection with i. \n",
    "\n",
    "d is the damping factor.\n",
    "\n",
    "The score is iteratively updated until convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:46.094408Z",
     "start_time": "2018-11-05T13:10:45.780316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converging at iteration 29....\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERATIONS = 50\n",
    "d=0.85\n",
    "threshold = 0.0001 #convergence threshold\n",
    "\n",
    "for iter in range(0,MAX_ITERATIONS):\n",
    "    prev_score = np.copy(score)\n",
    "    \n",
    "    for i in range(0,vocab_len):\n",
    "        \n",
    "        summation = 0\n",
    "        for j in range(0,vocab_len):\n",
    "            if weighted_edge[i][j] != 0:\n",
    "                summation += (weighted_edge[i][j]/inout[j])*score[j]\n",
    "                \n",
    "        score[i] = (1-d) + d*(summation)\n",
    "    \n",
    "    if np.sum(np.fabs(prev_score-score)) <= threshold: #convergence condition\n",
    "        print( \"Converging at iteration \"+str(iter)+\"....\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:48.897885Z",
     "start_time": "2018-11-05T13:10:48.876060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of больший: 1.1516752\n",
      "Score of сантиметр: 0.85898554\n",
      "Score of популярный: 0.45273048\n",
      "Score of использование: 1.356987\n",
      "Score of латекс: 0.7797809\n",
      "Score of масса: 0.8131534\n",
      "Score of усилие: 0.83935505\n",
      "Score of элегантность: 0.70660686\n",
      "Score of возможность: 0.6972453\n",
      "Score of размер: 0.74894476\n",
      "Score of место: 1.1955262\n",
      "Score of собранный: 0.7303076\n",
      "Score of послегарантийный: 0.47902593\n",
      "Score of мягкий: 0.73600566\n",
      "Score of компактный: 0.7962594\n",
      "Score of жилплощадь: 0.8380453\n",
      "Score of современный: 1.3552414\n",
      "Score of производство: 1.7572266\n",
      "Score of пружинный: 0.8548434\n",
      "Score of вид: 1.3042666\n",
      "Score of еврокнижка: 1.4513521\n",
      "Score of чрезвычайный: 0.6755964\n",
      "Score of продольный: 0.6805772\n",
      "Score of модельный: 0.6859055\n",
      "Score of обслуживание: 0.15\n",
      "Score of эффект: 0.71281666\n",
      "Score of ткань: 0.8135988\n",
      "Score of основа: 0.7951499\n",
      "Score of конструкция: 0.677244\n",
      "Score of габаритный: 0.74183095\n",
      "Score of тип: 0.85069686\n",
      "Score of гарантийный: 0.70578146\n",
      "Score of изготовление: 0.82140166\n",
      "Score of золото: 0.7123302\n",
      "Score of респект: 3.745745\n",
      "Score of чистый: 0.8277843\n",
      "Score of полудуга: 0.65868646\n",
      "Score of боковой: 0.7246771\n",
      "Score of удобный: 1.3065196\n",
      "Score of комфорт: 0.82987577\n",
      "Score of схема: 0.7417581\n",
      "Score of стильный: 0.7272209\n",
      "Score of пар: 0.8744981\n",
      "Score of минимум: 0.66646457\n",
      "Score of пружина: 0.8204192\n",
      "Score of короткий: 0.72130597\n",
      "Score of сидячий: 1.3153641\n",
      "Score of раскладка: 1.4084824\n",
      "Score of шерсть: 0.7643038\n",
      "Score of постельный: 0.74181753\n",
      "Score of материал: 0.6780094\n",
      "Score of вес: 0.78478044\n",
      "Score of ортопедический: 0.73430485\n",
      "Score of деревянный: 0.8002758\n",
      "Score of небольшой: 0.71939236\n",
      "Score of модель: 3.5624204\n",
      "Score of бельё: 0.74445677\n",
      "Score of наполнитель: 1.4361999\n",
      "Score of добавление: 0.721069\n",
      "Score of уют: 0.8569304\n",
      "Score of натуральный: 0.72280365\n",
      "Score of диван: 4.15722\n",
      "Score of механизм: 0.77106065\n",
      "Score of деловой: 0.77432925\n",
      "Score of особенность: 0.74733007\n",
      "Score of часть: 2.1346722\n",
      "Score of сидение: 0.7303784\n",
      "Score of преобразование: 0.8467838\n",
      "Score of хранение: 0.71658957\n",
      "Score of спальная: 0.72189856\n",
      "Score of позиция: 0.64632535\n",
      "Score of большинство: 0.70701593\n",
      "Score of ряд: 0.7216323\n",
      "Score of каркас: 0.797857\n",
      "Score of интерьер: 0.6507394\n",
      "Score of боннель: 0.87613416\n",
      "Score of полноценный: 0.820488\n",
      "Score of кровать: 0.78563607\n",
      "Score of кокос: 0.78507316\n",
      "Score of подушка: 0.6775213\n",
      "Score of частность: 0.7497363\n",
      "Score of квартира: 1.2783018\n",
      "Score of малогабаритный: 0.6947127\n",
      "Score of угловой: 3.9948473\n",
      "Score of змейка: 0.8014538\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,vocab_len):\n",
    "    print (\"Score of \"+vocabulary[i]+\": \"+str(score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Partiotioning\n",
    "\n",
    "Paritioning lemmatized_text into phrases using the stopwords in it as delimeters.\n",
    "The phrases are also candidates for keyphrases to be extracted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:55.100123Z",
     "start_time": "2018-11-05T13:10:55.096344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned Phrases (Candidate Keyphrases): \n",
      "\n",
      "[['популярный', 'позиция'], ['производство'], ['угловой', 'диван', 'респект'], ['современный'], ['деловой'], ['комфорт'], ['уют'], ['сантиметр', 'жилплощадь'], ['вес', 'золото'], ['угловой', 'диван', 'респект'], ['интерьер'], ['квартира'], ['минимум', 'место', 'угловой', 'диван', 'респект'], ['использование', 'удобный', 'мягкий'], ['современный'], ['компактный'], ['изготовление'], ['чистый', 'ткань'], ['наполнитель'], ['механизм', 'раскладка', 'еврокнижка'], ['масса', 'усилие'], ['преобразование'], ['полноценный', 'кровать', 'модель'], ['схема', 'раскладка', 'еврокнижка'], ['основа', 'деревянный', 'каркас'], ['использование', 'пружина', 'тип', 'боннель'], ['пар'], ['пружинный', 'змейка', 'особенность'], ['диван'], ['небольшой', 'габаритный', 'размер', 'короткий', 'часть', 'модель'], ['малогабаритный', 'квартира', 'стильный', 'боковой'], ['вид', 'полудуга'], ['угловой', 'диван', 'респект', 'чрезвычайный', 'элегантность'], ['большинство', 'модель'], ['производство'], ['модель', 'респект'], ['возможность', 'добавление'], ['спальная'], ['сидячий', 'часть', 'натуральный', 'наполнитель', 'кокос', 'латекс'], ['шерсть'], ['модель'], ['ортопедический', 'эффект'], ['конструкция', 'угловой', 'диван'], ['больший', 'место'], ['хранение', 'постельный', 'бельё'], ['сидячий', 'продольный', 'часть'], ['угловой', 'часть', 'угловой', 'диван', 'респект'], ['больший', 'подушка'], ['удобный', 'сидение'], ['собранный', 'вид'], ['материал'], ['производство', 'угловой', 'диван', 'респект'], ['модельный', 'ряд'], ['частность'], ['модель'], ['гарантийный']]\n"
     ]
    }
   ],
   "source": [
    "phrases = []\n",
    "\n",
    "phrase = \" \"\n",
    "for word in lemmatized_text:\n",
    "    if word in stopwords_plus:\n",
    "        if phrase!= \" \":\n",
    "            phrases.append(str(phrase).strip().split())\n",
    "        phrase = \" \"\n",
    "    elif word not in stopwords_plus:\n",
    "        phrase+=str(word)\n",
    "        phrase+=\" \"\n",
    "\n",
    "print(\"Partitioned Phrases (Candidate Keyphrases): \\n\")\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of unique phrases.\n",
    "\n",
    "Repeating phrases\\keyphrase candidates has no purpose here, anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:10:56.969821Z",
     "start_time": "2018-11-05T13:10:56.953836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Phrases (Candidate Keyphrases): \n",
      "\n",
      "[['популярный', 'позиция'], ['производство'], ['угловой', 'диван', 'респект'], ['современный'], ['деловой'], ['комфорт'], ['уют'], ['сантиметр', 'жилплощадь'], ['вес', 'золото'], ['интерьер'], ['квартира'], ['минимум', 'место', 'угловой', 'диван', 'респект'], ['использование', 'удобный', 'мягкий'], ['компактный'], ['изготовление'], ['чистый', 'ткань'], ['наполнитель'], ['механизм', 'раскладка', 'еврокнижка'], ['масса', 'усилие'], ['преобразование'], ['полноценный', 'кровать', 'модель'], ['схема', 'раскладка', 'еврокнижка'], ['основа', 'деревянный', 'каркас'], ['использование', 'пружина', 'тип', 'боннель'], ['пар'], ['пружинный', 'змейка', 'особенность'], ['диван'], ['небольшой', 'габаритный', 'размер', 'короткий', 'часть', 'модель'], ['малогабаритный', 'квартира', 'стильный', 'боковой'], ['вид', 'полудуга'], ['угловой', 'диван', 'респект', 'чрезвычайный', 'элегантность'], ['большинство', 'модель'], ['модель', 'респект'], ['возможность', 'добавление'], ['спальная'], ['сидячий', 'часть', 'натуральный', 'наполнитель', 'кокос', 'латекс'], ['шерсть'], ['модель'], ['ортопедический', 'эффект'], ['конструкция', 'угловой', 'диван'], ['больший', 'место'], ['хранение', 'постельный', 'бельё'], ['сидячий', 'продольный', 'часть'], ['угловой', 'часть', 'угловой', 'диван', 'респект'], ['больший', 'подушка'], ['удобный', 'сидение'], ['собранный', 'вид'], ['материал'], ['производство', 'угловой', 'диван', 'респект'], ['модельный', 'ряд'], ['частность'], ['гарантийный']]\n"
     ]
    }
   ],
   "source": [
    "unique_phrases = []\n",
    "\n",
    "for phrase in phrases:\n",
    "    if phrase not in unique_phrases:\n",
    "        unique_phrases.append(phrase)\n",
    "\n",
    "print(\"Unique Phrases (Candidate Keyphrases): \\n\")\n",
    "print(unique_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinning the list of candidate-keyphrases.\n",
    "\n",
    "Removing single word keyphrases-candidates that are present multi-word alternatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:26:49.073353Z",
     "start_time": "2018-11-05T13:26:49.059366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinned Unique Phrases (Candidate Keyphrases): \n",
      "\n",
      "[['популярный', 'позиция'], ['угловой', 'диван', 'респект'], ['современный'], ['деловой'], ['комфорт'], ['уют'], ['сантиметр', 'жилплощадь'], ['вес', 'золото'], ['интерьер'], ['минимум', 'место', 'угловой', 'диван', 'респект'], ['использование', 'удобный', 'мягкий'], ['компактный'], ['изготовление'], ['чистый', 'ткань'], ['механизм', 'раскладка', 'еврокнижка'], ['масса', 'усилие'], ['преобразование'], ['полноценный', 'кровать', 'модель'], ['схема', 'раскладка', 'еврокнижка'], ['основа', 'деревянный', 'каркас'], ['использование', 'пружина', 'тип', 'боннель'], ['пар'], ['пружинный', 'змейка', 'особенность'], ['небольшой', 'габаритный', 'размер', 'короткий', 'часть', 'модель'], ['малогабаритный', 'квартира', 'стильный', 'боковой'], ['вид', 'полудуга'], ['угловой', 'диван', 'респект', 'чрезвычайный', 'элегантность'], ['большинство', 'модель'], ['модель', 'респект'], ['возможность', 'добавление'], ['спальная'], ['сидячий', 'часть', 'натуральный', 'наполнитель', 'кокос', 'латекс'], ['шерсть'], ['ортопедический', 'эффект'], ['конструкция', 'угловой', 'диван'], ['больший', 'место'], ['хранение', 'постельный', 'бельё'], ['сидячий', 'продольный', 'часть'], ['угловой', 'часть', 'угловой', 'диван', 'респект'], ['больший', 'подушка'], ['удобный', 'сидение'], ['собранный', 'вид'], ['материал'], ['производство', 'угловой', 'диван', 'респект'], ['модельный', 'ряд'], ['частность'], ['гарантийный']]\n"
     ]
    }
   ],
   "source": [
    "for word in vocabulary:\n",
    "    #print word\n",
    "    for phrase in unique_phrases:\n",
    "        if (word in phrase) and ([word] in unique_phrases) and (len(phrase)>1):\n",
    "            #if len(phrase)>1 then the current phrase is multi-worded.\n",
    "            #if the word in vocabulary is present in unique_phrases as a single-word-phrase\n",
    "            # and at the same time present as a word within a multi-worded phrase,\n",
    "            # then I will remove the single-word-phrase from the list.\n",
    "            unique_phrases.remove([word])\n",
    "            \n",
    "print( \"Thinned Unique Phrases (Candidate Keyphrases): \\n\")\n",
    "print (unique_phrases)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Keyphrases\n",
    "\n",
    "Scoring the phrases (candidate keyphrases) and building up a list of keyphrases\\keywords\n",
    "by listing untokenized versions of tokenized phrases\\candidate-keyphrases.\n",
    "Phrases are scored by adding the score of their members (words\\text-units that were ranked by the graph algorithm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:26:50.989428Z",
     "start_time": "2018-11-05T13:26:50.967328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword: 'популярный позиция', Score: 1.099055826663971\n",
      "Keyword: 'угловой диван респект', Score: 11.897812128067017\n",
      "Keyword: 'современный', Score: 1.3552414178848267\n",
      "Keyword: 'деловой', Score: 0.7743292450904846\n",
      "Keyword: 'комфорт', Score: 0.8298757672309875\n",
      "Keyword: 'уют', Score: 0.8569303750991821\n",
      "Keyword: 'сантиметр жилплощадь', Score: 1.6970308423042297\n",
      "Keyword: 'вес золото', Score: 1.497110664844513\n",
      "Keyword: 'интерьер', Score: 0.6507393717765808\n",
      "Keyword: 'минимум место угловой диван респект', Score: 13.75980293750763\n",
      "Keyword: 'использование удобный мягкий', Score: 3.39951229095459\n",
      "Keyword: 'компактный', Score: 0.7962594032287598\n",
      "Keyword: 'изготовление', Score: 0.8214016556739807\n",
      "Keyword: 'чистый ткань', Score: 1.6413831114768982\n",
      "Keyword: 'механизм раскладка еврокнижка', Score: 3.63089519739151\n",
      "Keyword: 'масса усилие', Score: 1.6525084376335144\n",
      "Keyword: 'преобразование', Score: 0.8467838168144226\n",
      "Keyword: 'полноценный кровать модель', Score: 5.168544411659241\n",
      "Keyword: 'схема раскладка еврокнижка', Score: 3.6015926599502563\n",
      "Keyword: 'основа деревянный каркас', Score: 2.39328271150589\n",
      "Keyword: 'использование пружина тип боннель', Score: 3.90423721075058\n",
      "Keyword: 'пар', Score: 0.8744981288909912\n",
      "Keyword: 'пружинный змейка особенность', Score: 2.4036272764205933\n",
      "Keyword: 'небольшой габаритный размер короткий часть модель', Score: 8.628566563129425\n",
      "Keyword: 'малогабаритный квартира стильный боковой', Score: 3.4249125123023987\n",
      "Keyword: 'вид полудуга', Score: 1.9629530310630798\n",
      "Keyword: 'угловой диван респект чрезвычайный элегантность', Score: 13.280015408992767\n",
      "Keyword: 'большинство модель', Score: 4.269436299800873\n",
      "Keyword: 'модель респект', Score: 7.3081653118133545\n",
      "Keyword: 'возможность добавление', Score: 1.418314278125763\n",
      "Keyword: 'спальная', Score: 0.7218985557556152\n",
      "Keyword: 'сидячий часть натуральный наполнитель кокос латекс', Score: 7.173893928527832\n",
      "Keyword: 'шерсть', Score: 0.7643038034439087\n",
      "Keyword: 'ортопедический эффект', Score: 1.447121500968933\n",
      "Keyword: 'конструкция угловой диван', Score: 8.829311192035675\n",
      "Keyword: 'больший место', Score: 2.3472014665603638\n",
      "Keyword: 'хранение постельный бельё', Score: 2.202863872051239\n",
      "Keyword: 'сидячий продольный часть', Score: 4.1306135058403015\n",
      "Keyword: 'угловой часть угловой диван респект', Score: 18.027331590652466\n",
      "Keyword: 'больший подушка', Score: 1.8291965126991272\n",
      "Keyword: 'удобный сидение', Score: 2.0368980169296265\n",
      "Keyword: 'собранный вид', Score: 2.0345741510391235\n",
      "Keyword: 'материал', Score: 0.6780093908309937\n",
      "Keyword: 'производство угловой диван респект', Score: 13.655038714408875\n",
      "Keyword: 'модельный ряд', Score: 1.407537817955017\n",
      "Keyword: 'частность', Score: 0.7497363090515137\n",
      "Keyword: 'гарантийный', Score: 0.7057814598083496\n"
     ]
    }
   ],
   "source": [
    "phrase_scores = []\n",
    "keywords = []\n",
    "for phrase in unique_phrases:\n",
    "    phrase_score=0\n",
    "    keyword = ''\n",
    "    for word in phrase:\n",
    "        keyword += str(word)\n",
    "        keyword += \" \"\n",
    "        phrase_score+=score[vocabulary.index(word)]\n",
    "    phrase_scores.append(phrase_score)\n",
    "    keywords.append(keyword.strip())\n",
    "\n",
    "i=0\n",
    "for keyword in keywords:\n",
    "    print (\"Keyword: '\"+str(keyword)+\"', Score: \"+str(phrase_scores[i]))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:29:01.738892Z",
     "start_time": "2018-11-05T13:29:01.732694Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_keywords = [kw for kw in keywords  if len(kw.split())<=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:29:02.888731Z",
     "start_time": "2018-11-05T13:29:02.878104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['популярный позиция',\n",
       " 'угловой диван респект',\n",
       " 'современный',\n",
       " 'деловой',\n",
       " 'комфорт',\n",
       " 'уют',\n",
       " 'сантиметр жилплощадь',\n",
       " 'вес золото',\n",
       " 'интерьер',\n",
       " 'использование удобный мягкий',\n",
       " 'компактный',\n",
       " 'изготовление',\n",
       " 'чистый ткань',\n",
       " 'механизм раскладка еврокнижка',\n",
       " 'масса усилие',\n",
       " 'преобразование',\n",
       " 'полноценный кровать модель',\n",
       " 'схема раскладка еврокнижка',\n",
       " 'основа деревянный каркас',\n",
       " 'использование пружина тип боннель',\n",
       " 'пар',\n",
       " 'пружинный змейка особенность',\n",
       " 'малогабаритный квартира стильный боковой',\n",
       " 'вид полудуга',\n",
       " 'большинство модель',\n",
       " 'модель респект',\n",
       " 'возможность добавление',\n",
       " 'спальная',\n",
       " 'шерсть',\n",
       " 'ортопедический эффект',\n",
       " 'конструкция угловой диван',\n",
       " 'больший место',\n",
       " 'хранение постельный бельё',\n",
       " 'сидячий продольный часть',\n",
       " 'больший подушка',\n",
       " 'удобный сидение',\n",
       " 'собранный вид',\n",
       " 'материал',\n",
       " 'производство угловой диван респект',\n",
       " 'модельный ряд',\n",
       " 'частность',\n",
       " 'гарантийный']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking Keyphrases\n",
    "\n",
    "Ranking keyphrases based on their calculated scores. Displaying top keywords_num no. of keyphrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-05T13:11:01.767856Z",
     "start_time": "2018-11-05T13:11:01.748038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:\n",
      "\n",
      "угловой часть угловой диван респект, \n",
      "минимум место угловой диван респект, \n",
      "производство угловой диван респект, \n",
      "угловой диван респект чрезвычайный элегантность, \n",
      "угловой диван респект, \n",
      "конструкция угловой диван, \n",
      "небольшой габаритный размер короткий часть модель, \n",
      "модель респект, \n",
      "сидячий часть натуральный наполнитель кокос латекс, \n",
      "полноценный кровать модель, \n"
     ]
    }
   ],
   "source": [
    "sorted_index = np.flip(np.argsort(phrase_scores),0)\n",
    "\n",
    "keywords_num = 10\n",
    "\n",
    "print (\"Keywords:\\n\")\n",
    "\n",
    "for i in range(0,keywords_num):\n",
    "    print (str(keywords[sorted_index[i]])+\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input:\n",
    "\n",
    "Compatibility of systems of linear constraints over the set of natural numbers. Criteria of compatibility of a system of linear Diophantine equations, strict inequations, and nonstrict inequations are considered. Upper bounds for components of a minimal set of solutions and algorithms of construction of minimal generating sets of solutions for all types of systems are given. These criteria and the corresponding algorithms for constructing a minimal supporting set of solutions can be used in solving all the considered types of systems and systems of mixed types.\n",
    "\n",
    "# Extracted Keywords:\n",
    "\n",
    "* minimal supporting set,  \n",
    "* minimal generating set,  \n",
    "* minimal set,  \n",
    "* linear diophantine equation,  \n",
    "* nonstrict inequations,  \n",
    "* strict inequations,  \n",
    "* system,  \n",
    "* linear constraint,  \n",
    "* solution,  \n",
    "* upper bound, \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
